[project]
name = "linguagap"
version = "0.1.0"
description = "Real-time speech transcription and translation"
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.12"
authors = [
    { name = "Johann Hartmann", email = "johann@example.com" }
]
keywords = ["speech", "transcription", "translation", "asr", "whisper", "real-time"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Topic :: Multimedia :: Sound/Audio :: Speech",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.32.0",
    "numpy>=1.26.0",
    "python-multipart>=0.0.9",
    "httpx>=0.27.0",
    "websockets>=12.0",
    "huggingface-hub>=0.20.0",
    # Speaker diarization and language identification
    # PyTorch 2.8+ required for Blackwell GPUs (sm_120), needs CUDA 12.9 + cuDNN 9.8+
    "torch>=2.8.0",
    "torchaudio>=2.8.0",
    "pyannote.audio>=4.0.0", # 4.x required for PyTorch 2.6+ (weights_only=True fix)
    "omegaconf>=2.3.0", # Required by pyannote for loading pretrained models
    "speechbrain>=1.0.0",
    "hf-transfer>=0.1.9",
]

[project.optional-dependencies]
# ASR backends
asr-whisper = [
    "faster-whisper @ git+https://github.com/mayflower/faster-whisper.git", # Fork with segment.language attribute (PR #1274)
    "ctranslate2>=4.0.0",
]
# Translation backends
mt-translategemma = [
    "llama-cpp-python @ git+https://github.com/abetlen/llama-cpp-python.git@f42739945a70b9b592fc0e81a4b2ea4beebd4c50",
]
# Summarization backends (reuses llama-cpp-python from mt-translategemma)
summ-qwen3 = [
    "llama-cpp-python @ git+https://github.com/abetlen/llama-cpp-python.git@f42739945a70b9b592fc0e81a4b2ea4beebd4c50",
]

[project.urls]
Homepage = "https://github.com/johannhartmann/linguagap"
Repository = "https://github.com/johannhartmann/linguagap"
Issues = "https://github.com/johannhartmann/linguagap/issues"

[dependency-groups]
dev = [
    "ruff>=0.8.0",
    "ty>=0.0.1a3",
    "bandit>=1.7.0",
    "pre-commit>=4.0.0",
    "pytest>=8.0.0",
    "pytest-cov>=6.0.0",
    "pytest-asyncio>=0.24.0",
    "httpx>=0.27.0",
    # E2E test dependencies
    "google-genai>=1.0.0",  # Gemini dialogue gen + LLM-as-judge
    "google-cloud-texttospeech>=2.32.0",  # Cloud TTS API for Gemini TTS
    "pyyaml>=6.0",  # YAML dialogue templates
    "python-dotenv>=1.0.0",  # Load .env files
]

[tool.pytest.ini_options]
testpaths = ["tests"]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
addopts = "-v --tb=short"
markers = [
    "e2e: mark test as end-to-end test (requires GEMINI_API_KEY)",
    "slow: mark test as slow (deselect with '-m not slow')",
]

[tool.coverage.run]
source = ["src/app"]
branch = true
omit = ["*/scripts/*", "*/__pycache__/*"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if TYPE_CHECKING:",
    "if __name__ == .__main__.:",
]
show_missing = true

[tool.ruff]
target-version = "py312"
line-length = 100
src = ["src"]

[tool.ruff.lint]
select = [
    "E",      # pycodestyle errors
    "W",      # pycodestyle warnings
    "F",      # Pyflakes
    "I",      # isort
    "B",      # flake8-bugbear
    "C4",     # flake8-comprehensions
    "UP",     # pyupgrade
    "ARG",    # flake8-unused-arguments
    "SIM",    # flake8-simplify
]
ignore = [
    "E501",   # line too long (handled by formatter)
    "B008",   # function call in default argument (FastAPI pattern)
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.bandit]
exclude_dirs = ["tests"]
skips = ["B101"]  # assert statements

[tool.ty.environment]
python-version = "3.12"

[tool.ty.rules]
unresolved-import = "ignore"
invalid-argument-type = "ignore"  # llama-cpp-python complex types
non-subscriptable = "ignore"  # llama-cpp-python return types
possibly-missing-attribute = "ignore"  # llama-cpp-python nullable fields

[tool.uv.sources]
# Force torch packages from cu129 index for CUDA 12.9 / cuDNN 9.8+ compatibility
torch = { index = "pytorch-cu129" }
torchaudio = { index = "pytorch-cu129" }

[[tool.uv.index]]
name = "pytorch-cu129"
url = "https://download.pytorch.org/whl/cu129"
explicit = true
